# ğŸ§  HR Employee Attrition Prediction

## ğŸ“„ Overview
This project analyzes employee attrition using real-world HR data to identify patterns that lead to employee turnover.  
The goal was to build a reliable machine learning pipeline that predicts whether an employee is likely to leave the organization and helps HR teams act proactively.

We experimented with **multiple algorithms** â€” from interpretable statistical models to modern deep learning â€” to understand trade-offs between explainability, performance, and scalability.

---

## ğŸš€ Project Objectives
- Perform **exploratory data analysis (EDA)** to uncover factors driving attrition  
- Build a **machine learning pipeline** for preprocessing, feature encoding, and modeling  
- Compare multiple models:
  - **Logistic Regression** â†’ Baseline interpretability  
  - **Random Forest Classifier** â†’ Nonlinear performance benchmark  
  - **Neural Network (TensorFlow/Keras)** â†’ Deep relationship modeling  
- Evaluate performance and determine the most suitable approach

---

## ğŸ§© Dataset
- **Source:** [IBM HR Analytics Employee Attrition Dataset (Kaggle)](https://www.kaggle.com/pavansubhasht/ibm-hr-analytics-attrition-dataset)
- **Size:** 1470 rows Ã— 35 columns  
- **Target Variable:** `Attrition` (Yes / No)  
- **Key Features:**
  - Demographics (Age, Gender, MaritalStatus)  
  - Job-related (JobRole, Department, Overtime, YearsAtCompany)  
  - Satisfaction and performance metrics  

---

## âš™ï¸ Preprocessing
- Encoded binary and categorical features using **LabelEncoder** and **One-Hot Encoding**
- Removed irrelevant columns (`EmployeeNumber`, etc.)
- Standardized features using **StandardScaler**
- Split dataset into training and test sets (80/20 split with stratification)

---

## ğŸ§® Models Implemented

| Model | Purpose | Key Insights |
|--------|----------|--------------|
| **Logistic Regression** | Baseline linear model | High interpretability, shows direct feature impact |
| **Random Forest Classifier** | Ensemble model for nonlinear relationships | Captures feature interactions and improves accuracy |
| **Neural Network (TensorFlow)** | Deep model with hidden layers | Learns complex dependencies; strong generalization potential |

---

## ğŸ§  Model Comparison
| Metric | Logistic Regression | Random Forest | Neural Network |
|---------|--------------------|---------------|----------------|
| Interpretability | â­â­â­â­ | â­â­ | â­ |
| Accuracy | Moderate | High | High (with tuning) |
| Overfitting Risk | Low | Medium | High (regularized with Dropout) |
| Training Speed | Fast | Medium | Slow |
| Scalability | Good | Good | Excellent |

Each model served a purpose:
- **Logistic Regression** â†’ Business interpretability  
- **Random Forest** â†’ Balanced accuracy and feature interaction  
- **Neural Network** â†’ Captures deeper patterns and can scale with more data  

---

## ğŸ“ˆ Results
- Random Forest provided the best balance of **accuracy** and **stability** for tabular data.  
- Neural Network in TensorFlow achieved similar results but required careful tuning (batch size, learning rate, dropout).  
- Logistic Regression remained valuable for **explainable insights** in HR discussions.

---

## ğŸ§° Tech Stack
- **Languages:** Python  
- **Libraries:** Pandas, NumPy, Scikit-learn, Matplotlib, Seaborn, TensorFlow/Keras  
- **Environment:** Jupyter Notebook  

---

## ğŸ’¡ Future Improvements
- Handle class imbalance with **SMOTE** or **weighted loss**  
- Optimize neural network with **EarlyStopping** and **Learning Rate Scheduling**  
- Deploy via **Streamlit dashboard** for HR decision support  

---

## ğŸ§ Author
**Siddhardha Naidu Gorja**  
- Data Analyst & Machine Learning Enthusiast  
- Focused on applied analytics, automation, and real-world problem solving  
- [GitHub Profile](#) | [LinkedIn](#)
